# Nano-vLLM æºç åˆ†æè¯¾ç¨‹å¤§çº²

> ğŸš€ ä¸€ä¸ªè½»é‡çº§ vLLM å®ç°çš„æ·±åº¦æºç è§£æ

## è¯¾ç¨‹ç®€ä»‹

Nano-vLLM æ˜¯ä¸€ä¸ªä»…ç”¨çº¦ **1200 è¡Œ Python ä»£ç **å®ç°çš„è½»é‡çº§ LLM æ¨ç†å¼•æ“ï¼Œå´èƒ½è¾¾åˆ°ä¸ vLLM ç›¸å½“çš„æ¨ç†æ€§èƒ½ã€‚æœ¬è¯¾ç¨‹å°†å¸¦ä½ æ·±å…¥åˆ†ææ¯ä¸€è¡Œä»£ç ï¼Œç†è§£ç°ä»£ LLM æ¨ç†å¼•æ“çš„æ ¸å¿ƒè®¾è®¡ã€‚

### ğŸ¯ å­¦ä¹ ç›®æ ‡

é€šè¿‡æœ¬è¯¾ç¨‹ï¼Œä½ å°†æŒæ¡ï¼š

1. **LLM æ¨ç†å¼•æ“æ¶æ„**ï¼šç†è§£ Prefill/Decode ä¸¤é˜¶æ®µæ¨ç†
2. **KV Cache ç®¡ç†**ï¼šæŒæ¡åˆ†å—å­˜å‚¨ä¸ Prefix Caching
3. **é«˜æ•ˆè°ƒåº¦ç®—æ³•**ï¼šç†è§£ Continuous Batching ä¸æŠ¢å æœºåˆ¶
4. **å¼ é‡å¹¶è¡ŒæŠ€æœ¯**ï¼šæŒæ¡å¤š GPU å¹¶è¡Œæ¨ç†å®ç°
5. **æ€§èƒ½ä¼˜åŒ–æŠ€å·§**ï¼šCUDA Graphã€Torch Compileã€Flash Attention

### ğŸ“‹ å…ˆä¿®çŸ¥è¯†

- Python ç¼–ç¨‹åŸºç¡€
- PyTorch æ·±åº¦å­¦ä¹ æ¡†æ¶
- Transformer æ¨¡å‹æ¶æ„åŸºç¡€
- åŸºæœ¬çš„ CUDA ç¼–ç¨‹æ¦‚å¿µï¼ˆå¯é€‰ï¼‰

---

## è¯¾ç¨‹æ¶æ„

```mermaid
graph TB
    subgraph "ç¬¬ä¸€éƒ¨åˆ†: å…¥é—¨ä¸æ¶æ„"
        A[01 é¡¹ç›®æ¦‚è¿°] --> B[02 æ ¸å¿ƒæ¶æ„]
    end
    
    subgraph "ç¬¬äºŒéƒ¨åˆ†: é…ç½®ä¸æ•°æ®ç»“æ„"
        C[03 é…ç½®å‚æ•°] --> D[04 åºåˆ—ç®¡ç†]
    end
    
    subgraph "ç¬¬ä¸‰éƒ¨åˆ†: å¼•æ“æ ¸å¿ƒ"
        E[05 å—ç®¡ç†å™¨] --> F[06 è°ƒåº¦å™¨]
        F --> G[07 LLMå¼•æ“]
        G --> H[08 æ¨¡å‹è¿è¡Œå™¨]
    end
    
    subgraph "ç¬¬å››éƒ¨åˆ†: ç¥ç»ç½‘ç»œå±‚"
        I[09 çº¿æ€§å±‚] --> J[10 æ³¨æ„åŠ›]
        J --> K[11 ä½ç½®ç¼–ç ]
        K --> L[12 å½’ä¸€åŒ–]
        L --> M[13 åµŒå…¥å±‚]
        M --> N[14 é‡‡æ ·å™¨]
    end
    
    subgraph "ç¬¬äº”éƒ¨åˆ†: æ¨¡å‹å®ç°"
        O[15 Qwen3æ¨¡å‹] --> P[16 å·¥å…·æ¨¡å—]
    end
    
    subgraph "ç¬¬å…­éƒ¨åˆ†: é«˜çº§ä¸»é¢˜"
        Q[17 æ€§èƒ½ä¼˜åŒ–] --> R[18 æ€»ç»“]
    end
    
    B --> C
    D --> E
    H --> I
    N --> O
    P --> Q
```

---

## ç« èŠ‚ç›®å½•

### ç¬¬ä¸€éƒ¨åˆ†ï¼šå…¥é—¨ä¸æ¶æ„

| ç« èŠ‚ | æ ‡é¢˜ | æ ¸å¿ƒå†…å®¹ | æºæ–‡ä»¶ |
|:---:|:---|:---|:---|
| 01 | [é¡¹ç›®æ¦‚è¿°ä¸å¿«é€Ÿä¸Šæ‰‹](01_project_overview.md) | é¡¹ç›®ä»‹ç»ã€å®‰è£…ä½¿ç”¨ã€ä¸ vLLM å¯¹æ¯” | `README.md`, `example.py` |
| 02 | [æ ¸å¿ƒæ¶æ„æ€»è§ˆ](02_core_architecture.md) | æ•´ä½“æ¶æ„ã€æ•°æ®æµã€æ ¸å¿ƒæ¦‚å¿µ | å…¨å±€ |

### ç¬¬äºŒéƒ¨åˆ†ï¼šé…ç½®ä¸æ•°æ®ç»“æ„

| ç« èŠ‚ | æ ‡é¢˜ | æ ¸å¿ƒå†…å®¹ | æºæ–‡ä»¶ |
|:---:|:---|:---|:---|
| 03 | [é…ç½®ä¸é‡‡æ ·å‚æ•°](03_config_and_params.md) | Config ç±»ã€SamplingParams | `config.py`, `sampling_params.py` |
| 04 | [åºåˆ—ä¸çŠ¶æ€ç®¡ç†](04_sequence.md) | Sequence ç±»ã€çŠ¶æ€æœºã€åºåˆ—åŒ– | `sequence.py` |

### ç¬¬ä¸‰éƒ¨åˆ†ï¼šå¼•æ“æ ¸å¿ƒç»„ä»¶

| ç« èŠ‚ | æ ‡é¢˜ | æ ¸å¿ƒå†…å®¹ | æºæ–‡ä»¶ |
|:---:|:---|:---|:---|
| 05 | [KV Cache å—ç®¡ç†å™¨](05_block_manager.md) | åˆ†å—ç®¡ç†ã€Prefix Caching | `block_manager.py` |
| 06 | [è°ƒåº¦å™¨åŸç†](06_scheduler.md) | è°ƒåº¦ç®—æ³•ã€æŠ¢å æœºåˆ¶ | `scheduler.py` |
| 07 | [LLM å¼•æ“è¯¦è§£](07_llm_engine.md) | å¼•æ“å…¥å£ã€generate å¾ªç¯ | `llm_engine.py` |
| 08 | [æ¨¡å‹è¿è¡Œå™¨](08_model_runner.md) | åˆ†å¸ƒå¼ã€CUDA Graph | `model_runner.py` |

### ç¬¬å››éƒ¨åˆ†ï¼šç¥ç»ç½‘ç»œå±‚

| ç« èŠ‚ | æ ‡é¢˜ | æ ¸å¿ƒå†…å®¹ | æºæ–‡ä»¶ |
|:---:|:---|:---|:---|
| 09 | [çº¿æ€§å±‚ä¸å¼ é‡å¹¶è¡Œ](09_linear_layers.md) | åˆ—å¹¶è¡Œã€è¡Œå¹¶è¡Œã€QKV æŠ•å½± | `linear.py` |
| 10 | [æ³¨æ„åŠ›æœºåˆ¶](10_attention.md) | Flash Attentionã€KV Cache | `attention.py` |
| 11 | [RoPE ä½ç½®ç¼–ç ](11_rotary_embedding.md) | æ—‹è½¬ä½ç½®ç¼–ç å®ç° | `rotary_embedding.py` |
| 12 | [å½’ä¸€åŒ–ä¸æ¿€æ´»å‡½æ•°](12_normalization.md) | RMSNormã€SiLU | `layernorm.py`, `activation.py` |
| 13 | [è¯åµŒå…¥ä¸è¾“å‡ºå¤´](13_embedding_head.md) | å¹¶è¡ŒåµŒå…¥ã€LM Head | `embed_head.py` |
| 14 | [é‡‡æ ·å™¨](14_sampler.md) | æ¸©åº¦é‡‡æ ·ã€Gumbel-Max | `sampler.py` |

### ç¬¬äº”éƒ¨åˆ†ï¼šæ¨¡å‹ä¸å·¥å…·

| ç« èŠ‚ | æ ‡é¢˜ | æ ¸å¿ƒå†…å®¹ | æºæ–‡ä»¶ |
|:---:|:---|:---|:---|
| 15 | [Qwen3 æ¨¡å‹å®ç°](15_qwen3_model.md) | å®Œæ•´æ¨¡å‹æ¶æ„ | `qwen3.py` |
| 16 | [å·¥å…·æ¨¡å—](16_utils.md) | Contextã€æ¨¡å‹åŠ è½½ | `context.py`, `loader.py` |

### ç¬¬å…­éƒ¨åˆ†ï¼šé«˜çº§ä¸»é¢˜

| ç« èŠ‚ | æ ‡é¢˜ | æ ¸å¿ƒå†…å®¹ | æºæ–‡ä»¶ |
|:---:|:---|:---|:---|
| 17 | [æ€§èƒ½ä¼˜åŒ–æŠ€æœ¯](17_performance_optimization.md) | CUDA Graphã€Compile | `model_runner.py`, `bench.py` |
| 18 | [è¯¾ç¨‹æ€»ç»“ä¸æ‰©å±•](18_summary.md) | çŸ¥è¯†å›é¡¾ã€æ‰©å±•é˜…è¯» | - |

---

## é¡¹ç›®æ–‡ä»¶ç»“æ„

```
nano-vllm/
â”œâ”€â”€ nanovllm/
â”‚   â”œâ”€â”€ __init__.py          # åŒ…å…¥å£ï¼Œå¯¼å‡º LLM å’Œ SamplingParams
â”‚   â”œâ”€â”€ llm.py                # LLM ç±»ï¼ˆç»§æ‰¿è‡ª LLMEngineï¼‰
â”‚   â”œâ”€â”€ config.py             # é…ç½®ç±»
â”‚   â”œâ”€â”€ sampling_params.py    # é‡‡æ ·å‚æ•°
â”‚   â”œâ”€â”€ engine/
â”‚   â”‚   â”œâ”€â”€ llm_engine.py     # æ¨ç†å¼•æ“æ ¸å¿ƒ
â”‚   â”‚   â”œâ”€â”€ scheduler.py      # è°ƒåº¦å™¨
â”‚   â”‚   â”œâ”€â”€ block_manager.py  # KV Cache å—ç®¡ç†
â”‚   â”‚   â”œâ”€â”€ sequence.py       # åºåˆ—æ•°æ®ç»“æ„
â”‚   â”‚   â””â”€â”€ model_runner.py   # æ¨¡å‹è¿è¡Œå™¨
â”‚   â”œâ”€â”€ layers/
â”‚   â”‚   â”œâ”€â”€ linear.py         # å¹¶è¡Œçº¿æ€§å±‚
â”‚   â”‚   â”œâ”€â”€ attention.py      # æ³¨æ„åŠ›æœºåˆ¶
â”‚   â”‚   â”œâ”€â”€ rotary_embedding.py  # RoPE
â”‚   â”‚   â”œâ”€â”€ layernorm.py      # RMSNorm
â”‚   â”‚   â”œâ”€â”€ activation.py     # æ¿€æ´»å‡½æ•°
â”‚   â”‚   â”œâ”€â”€ embed_head.py     # åµŒå…¥å±‚å’Œè¾“å‡ºå¤´
â”‚   â”‚   â””â”€â”€ sampler.py        # é‡‡æ ·å™¨
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ qwen3.py          # Qwen3 æ¨¡å‹å®ç°
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ context.py        # ä¸Šä¸‹æ–‡ç®¡ç†
â”‚       â””â”€â”€ loader.py         # æ¨¡å‹åŠ è½½
â”œâ”€â”€ example.py                # ä½¿ç”¨ç¤ºä¾‹
â”œâ”€â”€ bench.py                  # æ€§èƒ½åŸºå‡†æµ‹è¯•
â””â”€â”€ README.md                 # é¡¹ç›®è¯´æ˜
```

---

## å­¦ä¹ å»ºè®®

### ğŸ“– æ¨èå­¦ä¹ é¡ºåº

1. **åŸºç¡€é˜¶æ®µ**ï¼ˆç¬¬ 1-4 ç« ï¼‰ï¼šç†è§£é¡¹ç›®ç»“æ„å’ŒåŸºç¡€æ•°æ®ç»“æ„
2. **æ ¸å¿ƒé˜¶æ®µ**ï¼ˆç¬¬ 5-8 ç« ï¼‰ï¼šæ·±å…¥å¼•æ“æ ¸å¿ƒç»„ä»¶
3. **å®ç°é˜¶æ®µ**ï¼ˆç¬¬ 9-16 ç« ï¼‰ï¼šé€å±‚åˆ†æç¥ç»ç½‘ç»œå®ç°
4. **è¿›é˜¶é˜¶æ®µ**ï¼ˆç¬¬ 17-18 ç« ï¼‰ï¼šæ€§èƒ½ä¼˜åŒ–ä¸æ€»ç»“

### ğŸ’¡ å­¦ä¹ æŠ€å·§

- å»ºè®®è¾¹è¯»è¾¹è¿è¡Œä»£ç ï¼ŒåŠ æ·±ç†è§£
- æ¯ç« ç»“æŸåå°è¯•ä¿®æ”¹ä»£ç éªŒè¯ç†è§£
- ç»“åˆ vLLM å®˜æ–¹æ–‡æ¡£å¯¹æ¯”å­¦ä¹ 

---

## å‚è€ƒèµ„æº

- [vLLM å®˜æ–¹æ–‡æ¡£](https://docs.vllm.ai/)
- [Flash Attention è®ºæ–‡](https://arxiv.org/abs/2205.14135)
- [Qwen3 æ¨¡å‹æ–‡æ¡£](https://huggingface.co/Qwen/Qwen3-0.6B)
- [PyTorch åˆ†å¸ƒå¼è®­ç»ƒæŒ‡å—](https://pytorch.org/tutorials/intermediate/ddp_tutorial.html)

---

**å¼€å§‹å­¦ä¹ ** â†’ [01 é¡¹ç›®æ¦‚è¿°ä¸å¿«é€Ÿä¸Šæ‰‹](01_project_overview.md)
