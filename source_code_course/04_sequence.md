# ç¬¬å››ç« ï¼šåºåˆ—ä¸çŠ¶æ€ç®¡ç†

> æœ¬ç« å°†é€è¡Œåˆ†æ `sequence.py`ï¼Œç†è§£åºåˆ—ï¼ˆSequenceï¼‰çš„æ•°æ®ç»“æ„å’ŒçŠ¶æ€ç®¡ç†æœºåˆ¶ã€‚

## 4.1 å®Œæ•´æºç 

```python
from copy import copy
from enum import Enum, auto
from itertools import count

from nanovllm.sampling_params import SamplingParams


class SequenceStatus(Enum):
    WAITING = auto()
    RUNNING = auto()
    FINISHED = auto()


class Sequence:
    block_size = 256
    counter = count()

    def __init__(self, token_ids: list[int], sampling_params = SamplingParams()):
        self.seq_id = next(Sequence.counter)
        self.status = SequenceStatus.WAITING
        self.token_ids = copy(token_ids)
        self.last_token = token_ids[-1]
        self.num_tokens = len(self.token_ids)
        self.num_prompt_tokens = len(token_ids)
        self.num_cached_tokens = 0
        self.block_table = []
        self.temperature = sampling_params.temperature
        self.max_tokens = sampling_params.max_tokens
        self.ignore_eos = sampling_params.ignore_eos

    def __len__(self):
        return self.num_tokens

    def __getitem__(self, key):
        return self.token_ids[key]

    @property
    def is_finished(self):
        return self.status == SequenceStatus.FINISHED

    @property
    def num_completion_tokens(self):
        return self.num_tokens - self.num_prompt_tokens

    @property
    def prompt_token_ids(self):
        return self.token_ids[:self.num_prompt_tokens]

    @property
    def completion_token_ids(self):
        return self.token_ids[self.num_prompt_tokens:]

    @property
    def num_cached_blocks(self):
        return self.num_cached_tokens // self.block_size

    @property
    def num_blocks(self):
        return (self.num_tokens + self.block_size - 1) // self.block_size

    @property
    def last_block_num_tokens(self):
        return self.num_tokens - (self.num_blocks - 1) * self.block_size

    def block(self, i):
        assert 0 <= i < self.num_blocks
        return self.token_ids[i*self.block_size: (i+1)*self.block_size]

    def append_token(self, token_id: int):
        self.token_ids.append(token_id)
        self.last_token = token_id
        self.num_tokens += 1

    def __getstate__(self):
        return (self.num_tokens, self.num_prompt_tokens, self.num_cached_tokens, self.block_table,
                self.token_ids if self.num_completion_tokens == 0 else self.last_token)

    def __setstate__(self, state):
        self.num_tokens, self.num_prompt_tokens, self.num_cached_tokens, self.block_table = state[:-1]
        if self.num_completion_tokens == 0:
            self.token_ids = state[-1]
        else:
            self.last_token = state[-1]
```

---

## 4.2 SequenceStatus æšä¸¾

### 4.2.1 æºç åˆ†æ

```python
class SequenceStatus(Enum):
    WAITING = auto()
    RUNNING = auto()
    FINISHED = auto()
```

### 4.2.2 çŠ¶æ€è¯´æ˜

| çŠ¶æ€ | å€¼ | è¯´æ˜ |
|:---|:---:|:---|
| `WAITING` | 1 | ç­‰å¾…è°ƒåº¦ï¼Œåœ¨ç­‰å¾…é˜Ÿåˆ—ä¸­ |
| `RUNNING` | 2 | æ­£åœ¨è¿è¡Œï¼Œåˆ†é…äº† GPU èµ„æº |
| `FINISHED` | 3 | å·²å®Œæˆï¼Œç”Ÿæˆäº† EOS æˆ–è¾¾åˆ°æœ€å¤§é•¿åº¦ |

### 4.2.3 çŠ¶æ€è½¬æ¢å›¾

```mermaid
stateDiagram-v2
    [*] --> WAITING: åˆ›å»ºåºåˆ—
    WAITING --> RUNNING: è°ƒåº¦å™¨åˆ†é…èµ„æº
    RUNNING --> WAITING: è¢«æŠ¢å 
    RUNNING --> FINISHED: ç”Ÿæˆå®Œæˆ
    FINISHED --> [*]: è¾“å‡ºç»“æœ
```

**çŠ¶æ€è½¬æ¢è§¦å‘æ¡ä»¶**ï¼š

| è½¬æ¢ | è§¦å‘ä½ç½® | æ¡ä»¶ |
|:---|:---|:---|
| WAITING â†’ RUNNING | `Scheduler.schedule()` | åºåˆ—è¢«è°ƒåº¦æ‰§è¡Œ |
| RUNNING â†’ WAITING | `Scheduler.preempt()` | å†…å­˜ä¸è¶³ï¼Œè¢«æŠ¢å  |
| RUNNING â†’ FINISHED | `Scheduler.postprocess()` | ç”Ÿæˆ EOS æˆ–è¾¾åˆ° max_tokens |

> ğŸ’¡ **è®¾è®¡æ€æƒ³**ï¼šä¸‰çŠ¶æ€æœºçš„è®¾è®¡ç®€æ´è€Œå®Œå¤‡ï¼Œ`RUNNING â†’ WAITING` çš„è½¬æ¢æ”¯æŒæŠ¢å æœºåˆ¶ï¼Œè¿™æ˜¯ Continuous Batching çš„å…³é”®â€”â€”å½“å†…å­˜ç´§å¼ æ—¶å¯ä»¥ä¸´æ—¶é‡Šæ”¾æŸäº›åºåˆ—çš„èµ„æºï¼Œè€Œä¸æ˜¯å®Œå…¨ä¸¢å¼ƒå·²è®¡ç®—çš„ç»“æœã€‚

---

## 4.3 Sequence ç±»è¯¦è§£

### 4.3.1 ç±»å˜é‡

```python
class Sequence:
    block_size = 256
    counter = count()
```

| å˜é‡ | ç±»å‹ | è¯´æ˜ |
|:---|:---|:---|
| `block_size` | `int` | KV Cache å—å¤§å°ï¼Œå…±äº«äºæ‰€æœ‰å®ä¾‹ |
| `counter` | `count` | å…¨å±€è®¡æ•°å™¨ï¼Œç”Ÿæˆå”¯ä¸€ seq_id |

**`count()` çš„ä½œç”¨**ï¼š

```python
from itertools import count

counter = count()
print(next(counter))  # 0
print(next(counter))  # 1
print(next(counter))  # 2
```

ç¡®ä¿æ¯ä¸ªåºåˆ—è·å¾—å”¯ä¸€çš„ IDã€‚

> ğŸ’¡ **è®¾è®¡æ€æƒ³**ï¼šä½¿ç”¨ç±»å˜é‡ `counter` è€Œéå®ä¾‹å˜é‡ï¼Œç¡®ä¿å…¨å±€å”¯ä¸€æ€§ã€‚`itertools.count()` æ˜¯æ— é™è¿­ä»£å™¨ï¼Œçº¿ç¨‹å®‰å…¨ä¸”æ°¸ä¸é‡å¤ï¼Œéå¸¸é€‚åˆç”Ÿæˆ IDã€‚

### 4.3.2 æ„é€ å‡½æ•°

```python
def __init__(self, token_ids: list[int], sampling_params = SamplingParams()):
    self.seq_id = next(Sequence.counter)        # å”¯ä¸€åºåˆ— ID
    self.status = SequenceStatus.WAITING        # åˆå§‹çŠ¶æ€ä¸ºç­‰å¾…
    self.token_ids = copy(token_ids)            # å¤åˆ¶ token åˆ—è¡¨
    self.last_token = token_ids[-1]             # æœ€åä¸€ä¸ª token
    self.num_tokens = len(self.token_ids)       # å½“å‰æ€» token æ•°
    self.num_prompt_tokens = len(token_ids)     # prompt é•¿åº¦ï¼ˆå›ºå®šï¼‰
    self.num_cached_tokens = 0                  # å·²ç¼“å­˜çš„ token æ•°
    self.block_table = []                       # å—è¡¨
    self.temperature = sampling_params.temperature
    self.max_tokens = sampling_params.max_tokens
    self.ignore_eos = sampling_params.ignore_eos
```

**é€è¡Œè§£æ**ï¼š

| è¡Œå· | å±æ€§ | è¯´æ˜ |
|:---:|:---|:---|
| 1 | `seq_id` | å…¨å±€å”¯ä¸€ IDï¼Œç”¨äºè¯†åˆ«åºåˆ— |
| 2 | `status` | åˆå§‹çŠ¶æ€ä¸º WAITING |
| 3 | `token_ids` | ä½¿ç”¨ `copy()` é¿å…ä¿®æ”¹åŸå§‹åˆ—è¡¨ |
| 4 | `last_token` | Decode é˜¶æ®µåªéœ€è¦æœ€åä¸€ä¸ª token |
| 5 | `num_tokens` | åŠ¨æ€æ›´æ–°ï¼ŒåŒ…å«å·²ç”Ÿæˆçš„ token |
| 6 | `num_prompt_tokens` | å›ºå®šä¸å˜ï¼ŒåŒºåˆ† prompt å’Œ completion |
| 7 | `num_cached_tokens` | Prefix Caching ä½¿ç”¨ |
| 8 | `block_table` | å­˜å‚¨åˆ†é…çš„å— ID åˆ—è¡¨ |
| 9-11 | é‡‡æ ·å‚æ•° | ä» SamplingParams å¤åˆ¶ |

> ğŸ’¡ **è®¾è®¡æ€æƒ³**ï¼šä½¿ç”¨ `copy(token_ids)` è€Œéç›´æ¥å¼•ç”¨ï¼Œé¿å…å¤–éƒ¨ä¿®æ”¹å½±å“åºåˆ—å†…éƒ¨çŠ¶æ€ï¼Œä½“ç°äº†ã€Œé˜²å¾¡æ€§å¤åˆ¶ã€çš„ç¼–ç¨‹å®è·µã€‚å°†é‡‡æ ·å‚æ•°å±•å¼€å­˜å‚¨è€Œéä¿ç•™å¯¹è±¡å¼•ç”¨ï¼Œè¢«å…å¯¹è±¡å›¾å¤æ‚åŒ–ã€‚

### 4.3.3 å†…å­˜å¸ƒå±€ç¤ºæ„

```mermaid
graph TB
    subgraph "Sequence å¯¹è±¡"
        A[seq_id: 0]
        B[status: RUNNING]
        C[token_ids: 512 ä¸ª token]
        D[num_prompt_tokens: 100]
        E[num_tokens: 512]
        F[num_cached_tokens: 256]
        G[block_table: #91;0, 5, 12#93;]
    end
    
    subgraph "Token åˆ†å¸ƒ"
        H["Prompt (100)"]
        I["Completion (412)"]
    end
    
    subgraph "Block æ˜ å°„"
        J["Block 0: token 0-255"]
        K["Block 5: token 256-511"]
        L["Block 12: token 512+"]
    end
    
    C --> H
    C --> I
    G --> J
    G --> K
    G --> L
```

---

## 4.4 é­”æœ¯æ–¹æ³•

### 4.4.1 `__len__` å’Œ `__getitem__`

```python
def __len__(self):
    return self.num_tokens

def __getitem__(self, key):
    return self.token_ids[key]
```

**ä½œç”¨**ï¼š

```python
seq = Sequence([1, 2, 3, 4, 5])
print(len(seq))     # 5
print(seq[0])       # 1
print(seq[1:3])     # [2, 3]
print(seq[-1])      # 5
```

ä½¿ `Sequence` å¯ä»¥åƒåˆ—è¡¨ä¸€æ ·ä½¿ç”¨ã€‚

> ğŸ’¡ **è®¾è®¡æ€æƒ³**ï¼šå®ç° `__len__` å’Œ `__getitem__` è®© `Sequence` éµå¾ª Python çš„åºåˆ—åè®®ï¼Œå¯ä»¥ç›´æ¥ç”¨äº `len()`ã€åˆ‡ç‰‡ã€è¿­ä»£ç­‰æ“ä½œï¼Œè®©ä»£ç æ›´ç¬¦åˆ Python ä¹ æƒ¯ã€‚

---

## 4.5 å±æ€§æ–¹æ³•

### 4.5.1 çŠ¶æ€å±æ€§

```python
@property
def is_finished(self):
    return self.status == SequenceStatus.FINISHED
```

ç®€æ´åœ°åˆ¤æ–­åºåˆ—æ˜¯å¦å®Œæˆã€‚

### 4.5.2 Token è®¡æ•°å±æ€§

```python
@property
def num_completion_tokens(self):
    return self.num_tokens - self.num_prompt_tokens
```

**è®¡ç®—é€»è¾‘**ï¼š

```
æ€» token æ•° - prompt token æ•° = å·²ç”Ÿæˆçš„ token æ•°
```

**ç¤ºä¾‹**ï¼š

```python
seq = Sequence([1, 2, 3])  # 3 ä¸ª prompt tokens
seq.append_token(4)
seq.append_token(5)
print(seq.num_prompt_tokens)      # 3
print(seq.num_tokens)             # 5
print(seq.num_completion_tokens)  # 2
```

### 4.5.3 Token ID åˆ‡ç‰‡å±æ€§

```python
@property
def prompt_token_ids(self):
    return self.token_ids[:self.num_prompt_tokens]

@property
def completion_token_ids(self):
    return self.token_ids[self.num_prompt_tokens:]
```

**å¯è§†åŒ–**ï¼š

```
token_ids: [p1, p2, p3, c1, c2, c3, c4]
            |---------|  |------------|
         prompt_token_ids  completion_token_ids
```

---

## 4.6 å—ç®¡ç†ç›¸å…³

### 4.6.1 å—è®¡ç®—å±æ€§

```python
@property
def num_cached_blocks(self):
    return self.num_cached_tokens // self.block_size

@property
def num_blocks(self):
    return (self.num_tokens + self.block_size - 1) // self.block_size

@property
def last_block_num_tokens(self):
    return self.num_tokens - (self.num_blocks - 1) * self.block_size
```

**è®¡ç®—ç¤ºä¾‹**ï¼ˆå‡è®¾ `block_size=256`ï¼‰ï¼š

| å±æ€§ | å…¬å¼ | ç¤ºä¾‹ (num_tokens=600) |
|:---|:---|:---|
| `num_blocks` | `âŒˆnum_tokens / block_sizeâŒ‰` | `âŒˆ600/256âŒ‰ = 3` |
| `last_block_num_tokens` | `num_tokens - (num_blocks-1) * block_size` | `600 - 2*256 = 88` |

**å¯è§†åŒ–**ï¼š

```
tokens (600ä¸ª):
|-------- Block 0 --------|-------- Block 1 --------|-- Block 2 --|
[     256 tokens          ][     256 tokens          ][  88 tokens ]
                                                       â†‘
                                           last_block_num_tokens = 88
```

### 4.6.2 è·å–ç‰¹å®šå—

```python
def block(self, i):
    assert 0 <= i < self.num_blocks
    return self.token_ids[i*self.block_size: (i+1)*self.block_size]
```

**ä½œç”¨**ï¼šè·å–ç¬¬ i ä¸ªå—ä¸­çš„ token IDsï¼Œç”¨äºè®¡ç®— Prefix Caching çš„å“ˆå¸Œå€¼ã€‚

---

## 4.7 Token è¿½åŠ 

```python
def append_token(self, token_id: int):
    self.token_ids.append(token_id)
    self.last_token = token_id
    self.num_tokens += 1
```

**è°ƒç”¨æ—¶æœº**ï¼š`Scheduler.postprocess()` åœ¨æ¯æ¬¡ decode æ­¥éª¤åè°ƒç”¨ã€‚

**æµç¨‹**ï¼š

```mermaid
sequenceDiagram
    participant Sched as Scheduler
    participant Seq as Sequence
    
    Sched->>Seq: append_token(new_token_id)
    Seq->>Seq: token_ids.append(new_token_id)
    Seq->>Seq: last_token = new_token_id
    Seq->>Seq: num_tokens += 1
```

---

## 4.8 åºåˆ—åŒ–æ–¹æ³•

### 4.8.1 `__getstate__`

```python
def __getstate__(self):
    return (self.num_tokens, self.num_prompt_tokens, self.num_cached_tokens, self.block_table,
            self.token_ids if self.num_completion_tokens == 0 else self.last_token)
```

**è®¾è®¡äº®ç‚¹**ï¼š

- **Prefill é˜¶æ®µ**ï¼šä¼ è¾“å®Œæ•´ `token_ids`ï¼ˆéœ€è¦è®¡ç®—æ‰€æœ‰ tokenï¼‰
- **Decode é˜¶æ®µ**ï¼šåªä¼ è¾“ `last_token`ï¼ˆåªéœ€è¦æœ€åä¸€ä¸ª tokenï¼‰

```mermaid
graph TD
    A{num_completion_tokens == 0?}
    A -->|æ˜¯ #40;Prefill#41;| B[ä¼ è¾“å®Œæ•´ token_ids]
    A -->|å¦ #40;Decode#41;| C[ä»…ä¼ è¾“ last_token]
```

**ä¼˜åŒ–æ•ˆæœ**ï¼š

| é˜¶æ®µ | ä¼ è¾“æ•°æ®é‡ | è¯´æ˜ |
|:---|:---|:---|
| Prefill | O(n) | å®Œæ•´ prompt tokens |
| Decode | O(1) | ä»… 1 ä¸ª token |

> ğŸ’¡ **è®¾è®¡æ€æƒ³**ï¼šåºåˆ—åŒ–ä¼˜åŒ–æ˜¯å¼ é‡å¹¶è¡Œçš„å…³é”®â€”â€”Decode é˜¶æ®µåªä¼ è¾“ 1 ä¸ª token è€Œéå…¨é‡ token_idsï¼Œå¤§å¹…å‡å°‘è¿›ç¨‹é—´é€šä¿¡å¼€é”€ã€‚è¿™æ˜¯å…¸å‹çš„ã€Œå¢é‡ä¼ è¾“ã€æ€æƒ³ï¼Œåªä¼ é€’å¿…è¦çš„ä¿¡æ¯ã€‚

### 4.8.2 `__setstate__`

```python
def __setstate__(self, state):
    self.num_tokens, self.num_prompt_tokens, self.num_cached_tokens, self.block_table = state[:-1]
    if self.num_completion_tokens == 0:
        self.token_ids = state[-1]
    else:
        self.last_token = state[-1]
```

ååºåˆ—åŒ–æ—¶æ ¹æ® `num_completion_tokens` åˆ¤æ–­çŠ¶æ€çš„æœ€åä¸€ä¸ªå…ƒç´ æ˜¯ `token_ids` è¿˜æ˜¯ `last_token`ã€‚

### 4.8.3 åºåˆ—åŒ–ç”¨é€”

```mermaid
sequenceDiagram
    participant R0 as Rank 0
    participant SHM as å…±äº«å†…å­˜
    participant R1 as Rank 1
    
    R0->>R0: pickle.dumps(sequences)
    Note right of R0: è°ƒç”¨ __getstate__
    R0->>SHM: å†™å…¥åºåˆ—åŒ–æ•°æ®
    SHM->>R1: è¯»å–æ•°æ®
    R1->>R1: pickle.loads(data)
    Note right of R1: è°ƒç”¨ __setstate__
```

åœ¨å¤š GPU å¼ é‡å¹¶è¡Œä¸­ï¼Œä¸»è¿›ç¨‹éœ€è¦å°†åºåˆ—ä¿¡æ¯ä¼ é€’ç»™å…¶ä»–è¿›ç¨‹ã€‚

---

## 4.9 å®Œæ•´ç¤ºä¾‹

```python
from nanovllm.engine.sequence import Sequence, SequenceStatus
from nanovllm.sampling_params import SamplingParams

# åˆ›å»ºåºåˆ—
params = SamplingParams(temperature=0.6, max_tokens=100)
seq = Sequence([101, 102, 103, 104, 105], params)

# åŸºæœ¬ä¿¡æ¯
print(f"seq_id: {seq.seq_id}")           # 0
print(f"status: {seq.status}")           # WAITING
print(f"len: {len(seq)}")                # 5
print(f"prompt_tokens: {seq.prompt_token_ids}")  # [101, 102, 103, 104, 105]

# æ¨¡æ‹Ÿè°ƒåº¦
seq.status = SequenceStatus.RUNNING

# æ¨¡æ‹Ÿç”Ÿæˆ
seq.append_token(201)
seq.append_token(202)

print(f"completion_tokens: {seq.completion_token_ids}")  # [201, 202]
print(f"num_completion: {seq.num_completion_tokens}")    # 2

# å—è®¡ç®—
print(f"num_blocks: {seq.num_blocks}")   # 1 (7 tokens / 256 = 1 block)
```

---

## 4.10 æœ¬ç« å°ç»“

æœ¬ç« æˆ‘ä»¬å­¦ä¹ äº†ï¼š

1. **SequenceStatus**ï¼šä¸‰ç§çŠ¶æ€ï¼ˆWAITINGã€RUNNINGã€FINISHEDï¼‰åŠè½¬æ¢æ¡ä»¶
2. **Sequence ç±»å˜é‡**ï¼š`block_size` å’Œ `counter` çš„è®¾è®¡
3. **å®ä¾‹å±æ€§**ï¼štoken_idsã€çŠ¶æ€ã€å—è¡¨ç­‰æ ¸å¿ƒå±æ€§
4. **å±æ€§æ–¹æ³•**ï¼šä¾¿æ·è®¿é—® completion tokensã€å—æ•°ç­‰
5. **å—ç®¡ç†**ï¼š`num_blocks`ã€`last_block_num_tokens`ã€`block()` æ–¹æ³•
6. **åºåˆ—åŒ–ä¼˜åŒ–**ï¼šDecode é˜¶æ®µåªä¼ è¾“ `last_token`

---

**ä¸‹ä¸€ç« ** â†’ [05 KV Cache å—ç®¡ç†å™¨](05_block_manager.md)
