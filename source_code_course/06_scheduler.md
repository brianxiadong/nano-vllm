# ç¬¬å…­ç« ï¼šè°ƒåº¦å™¨åŸç†

> æœ¬ç« å°†é€è¡Œåˆ†æ `scheduler.py`ï¼Œç†è§£ Nano-vLLM çš„è°ƒåº¦ç®—æ³•å’ŒæŠ¢å æœºåˆ¶ã€‚

## 6.1 è°ƒåº¦å™¨æ¦‚è¿°

### 6.1.1 è°ƒåº¦å™¨çš„èŒè´£

```mermaid
graph TB
    subgraph "è°ƒåº¦å™¨èŒè´£"
        A[ç®¡ç†è¯·æ±‚é˜Ÿåˆ—]
        B[åˆ†é…è®¡ç®—èµ„æº]
        C[å¤„ç†æŠ¢å ]
        D[åå¤„ç†ç»“æœ]
    end
    
    subgraph "è¾“å…¥"
        E[waiting é˜Ÿåˆ—]
        F[running é˜Ÿåˆ—]
    end
    
    subgraph "è¾“å‡º"
        G[æœ¬è½®æ‰§è¡Œçš„åºåˆ—]
        H[æ‰§è¡Œæ¨¡å¼: Prefill/Decode]
    end
    
    E --> A
    F --> A
    A --> B
    B --> C
    C --> G
    C --> H
```

---

## 6.2 å®Œæ•´æºç 

```python
from collections import deque

from nanovllm.config import Config
from nanovllm.engine.sequence import Sequence, SequenceStatus
from nanovllm.engine.block_manager import BlockManager


class Scheduler:

    def __init__(self, config: Config):
        self.max_num_seqs = config.max_num_seqs
        self.max_num_batched_tokens = config.max_num_batched_tokens
        self.eos = config.eos
        self.block_manager = BlockManager(config.num_kvcache_blocks, config.kvcache_block_size)
        self.waiting: deque[Sequence] = deque()
        self.running: deque[Sequence] = deque()

    def is_finished(self):
        return not self.waiting and not self.running

    def add(self, seq: Sequence):
        self.waiting.append(seq)

    def schedule(self) -> tuple[list[Sequence], bool]:
        # prefill
        scheduled_seqs = []
        num_seqs = 0
        num_batched_tokens = 0
        while self.waiting and num_seqs < self.max_num_seqs:
            seq = self.waiting[0]
            if num_batched_tokens + len(seq) > self.max_num_batched_tokens or not self.block_manager.can_allocate(seq):
                break
            num_seqs += 1
            self.block_manager.allocate(seq)
            num_batched_tokens += len(seq) - seq.num_cached_tokens
            seq.status = SequenceStatus.RUNNING
            self.waiting.popleft()
            self.running.append(seq)
            scheduled_seqs.append(seq)
        if scheduled_seqs:
            return scheduled_seqs, True

        # decode
        while self.running and num_seqs < self.max_num_seqs:
            seq = self.running.popleft()
            while not self.block_manager.can_append(seq):
                if self.running:
                    self.preempt(self.running.pop())
                else:
                    self.preempt(seq)
                    break
            else:
                num_seqs += 1
                self.block_manager.may_append(seq)
                scheduled_seqs.append(seq)
        assert scheduled_seqs
        self.running.extendleft(reversed(scheduled_seqs))
        return scheduled_seqs, False

    def preempt(self, seq: Sequence):
        seq.status = SequenceStatus.WAITING
        self.block_manager.deallocate(seq)
        self.waiting.appendleft(seq)

    def postprocess(self, seqs: list[Sequence], token_ids: list[int]) -> list[bool]:
        for seq, token_id in zip(seqs, token_ids):
            seq.append_token(token_id)
            if (not seq.ignore_eos and token_id == self.eos) or seq.num_completion_tokens == seq.max_tokens:
                seq.status = SequenceStatus.FINISHED
                self.block_manager.deallocate(seq)
                self.running.remove(seq)
```

---

## 6.3 æ„é€ å‡½æ•°

```python
def __init__(self, config: Config):
    self.max_num_seqs = config.max_num_seqs
    self.max_num_batched_tokens = config.max_num_batched_tokens
    self.eos = config.eos
    self.block_manager = BlockManager(config.num_kvcache_blocks, config.kvcache_block_size)
    self.waiting: deque[Sequence] = deque()
    self.running: deque[Sequence] = deque()
```

### é€è¡Œè§£æ

| è¡Œå· | å±æ€§ | è¯´æ˜ |
|:---:|:---|:---|
| 1 | `max_num_seqs` | æœ€å¤§å¹¶å‘åºåˆ—æ•°ï¼ˆé»˜è®¤ 512ï¼‰ |
| 2 | `max_num_batched_tokens` | å•æ‰¹æ¬¡æœ€å¤§ token æ•°ï¼ˆé»˜è®¤ 16384ï¼‰ |
| 3 | `eos` | ç»“æŸ token ID |
| 4 | `block_manager` | KV Cache å—ç®¡ç†å™¨ |
| 5 | `waiting` | ç­‰å¾…é˜Ÿåˆ—ï¼ˆFIFOï¼‰ |
| 6 | `running` | è¿è¡Œé˜Ÿåˆ— |

> ğŸ’¡ **è®¾è®¡æ€æƒ³**ï¼šä½¿ç”¨ `deque` è€Œé `list` å®ç°é˜Ÿåˆ—ï¼Œå› ä¸º `deque` çš„å¤´å°¾æ“ä½œéƒ½æ˜¯ O(1)ã€‚å°† `BlockManager` å†…åµŒåœ¨è°ƒåº¦å™¨ä¸­ï¼Œä½“ç°äº†ã€Œç»„åˆä¼˜äºç»§æ‰¿ã€çš„è®¾è®¡åŸåˆ™ã€‚

### é˜Ÿåˆ—ç®¡ç†å›¾

```mermaid
graph LR
    subgraph "ç­‰å¾…é˜Ÿåˆ— waiting"
        W1["Seq 5"] --> W2["Seq 6"] --> W3["Seq 7"]
    end
    
    subgraph "è¿è¡Œé˜Ÿåˆ— running"
        R1["Seq 1"] --> R2["Seq 2"] --> R3["Seq 3"]
    end
    
    W1 -.->|"è°ƒåº¦"| R3
    R1 -.->|"å®Œæˆ"| F[è¾“å‡º]
    R3 -.->|"æŠ¢å "| W1
```

---

## 6.4 è¾…åŠ©æ–¹æ³•

### 6.4.1 is_finished

```python
def is_finished(self):
    return not self.waiting and not self.running
```

å½“ä¸¤ä¸ªé˜Ÿåˆ—éƒ½ä¸ºç©ºæ—¶ï¼Œæ‰€æœ‰è¯·æ±‚å¤„ç†å®Œæˆã€‚

### 6.4.2 add

```python
def add(self, seq: Sequence):
    self.waiting.append(seq)
```

æ–°è¯·æ±‚åŠ å…¥ç­‰å¾…é˜Ÿåˆ—å°¾éƒ¨ã€‚

---

## 6.5 è°ƒåº¦ç®—æ³•ï¼ˆæ ¸å¿ƒï¼‰

### 6.5.1 Prefill è°ƒåº¦

```python
def schedule(self) -> tuple[list[Sequence], bool]:
    # prefill
    scheduled_seqs = []
    num_seqs = 0
    num_batched_tokens = 0
    
    while self.waiting and num_seqs < self.max_num_seqs:
        seq = self.waiting[0]                           # æŸ¥çœ‹é˜Ÿé¦–
        
        # æ£€æŸ¥çº¦æŸ
        if num_batched_tokens + len(seq) > self.max_num_batched_tokens or \
           not self.block_manager.can_allocate(seq):
            break
        
        # è°ƒåº¦æ­¤åºåˆ—
        num_seqs += 1
        self.block_manager.allocate(seq)                # åˆ†é… KV Cache
        num_batched_tokens += len(seq) - seq.num_cached_tokens  # å®é™…éœ€è®¡ç®—çš„ token
        seq.status = SequenceStatus.RUNNING             # æ›´æ–°çŠ¶æ€
        self.waiting.popleft()                          # ä»ç­‰å¾…é˜Ÿåˆ—ç§»é™¤
        self.running.append(seq)                        # åŠ å…¥è¿è¡Œé˜Ÿåˆ—
        scheduled_seqs.append(seq)                      # åŠ å…¥æœ¬è½®è°ƒåº¦
    
    if scheduled_seqs:
        return scheduled_seqs, True                     # True = Prefill æ¨¡å¼
```

### Prefill è°ƒåº¦æµç¨‹å›¾

```mermaid
flowchart TD
    A[å¼€å§‹è°ƒåº¦] --> B{waiting éç©ºä¸”<br/>num_seqs < max?}
    B -->|å¦| C{scheduled_seqs éç©º?}
    B -->|æ˜¯| D[å–é˜Ÿé¦– seq]
    D --> E{token æ•°è¶…é™?}
    E -->|æ˜¯| C
    E -->|å¦| F{èƒ½åˆ†é…å†…å­˜?}
    F -->|å¦| C
    F -->|æ˜¯| G[åˆ†é… KV Cache]
    G --> H[æ›´æ–°è®¡æ•°]
    H --> I[æ›´æ–°çŠ¶æ€ä¸º RUNNING]
    I --> J[ç§»å…¥ running é˜Ÿåˆ—]
    J --> K[æ·»åŠ åˆ° scheduled_seqs]
    K --> B
    C -->|æ˜¯| L[è¿”å› Prefill æ¨¡å¼]
    C -->|å¦| M[è¿›å…¥ Decode è°ƒåº¦]
```

### 6.5.2 Decode è°ƒåº¦

```python
    # decode
    while self.running and num_seqs < self.max_num_seqs:
        seq = self.running.popleft()                    # å–å‡ºé˜Ÿé¦–
        
        while not self.block_manager.can_append(seq):   # å†…å­˜ä¸è¶³
            if self.running:
                self.preempt(self.running.pop())        # æŠ¢å é˜Ÿå°¾åºåˆ—
            else:
                self.preempt(seq)                       # æŠ¢å è‡ªå·±
                break
        else:
            # æˆåŠŸåˆ†é…
            num_seqs += 1
            self.block_manager.may_append(seq)
            scheduled_seqs.append(seq)
    
    assert scheduled_seqs                               # è‡³å°‘æœ‰ä¸€ä¸ªåºåˆ—
    self.running.extendleft(reversed(scheduled_seqs))   # æ”¾å›é˜Ÿé¦–
    return scheduled_seqs, False                        # False = Decode æ¨¡å¼
```

### Decode è°ƒåº¦æµç¨‹å›¾

```mermaid
flowchart TD
    A[Decode è°ƒåº¦] --> B{running éç©ºä¸”<br/>num_seqs < max?}
    B -->|å¦| C[scheduled_seqs æ”¾å›é˜Ÿé¦–]
    B -->|æ˜¯| D[å–é˜Ÿé¦– seq]
    D --> E{èƒ½è¿½åŠ å†…å­˜?}
    E -->|æ˜¯| F[may_append]
    E -->|å¦| G{running éç©º?}
    G -->|æ˜¯| H[æŠ¢å é˜Ÿå°¾åºåˆ—]
    G -->|å¦| I[æŠ¢å å½“å‰ seq]
    H --> E
    I --> J[è·³è¿‡æ­¤ seq]
    F --> K[æ·»åŠ åˆ° scheduled_seqs]
    K --> B
    J --> B
    C --> L[è¿”å› Decode æ¨¡å¼]
```

### 6.5.3 å…³é”®è®¾è®¡

**ä¸ºä»€ä¹ˆ Prefill ä¼˜å…ˆäº Decodeï¼Ÿ**

1. **é¿å…é¥¥é¥¿**ï¼šæ–°è¯·æ±‚ä¸ä¼šæ°¸è¿œç­‰å¾…
2. **æ‰¹å¤„ç†æ•ˆç‡**ï¼šPrefill å¯ä»¥å¹¶è¡Œå¤„ç†å¤šä¸ªåºåˆ—
3. **èµ„æºåˆ©ç”¨**ï¼šå…ˆå¡«æ»¡ GPU è®¡ç®—èƒ½åŠ›

**`running.extendleft(reversed(scheduled_seqs))` çš„ä½œç”¨**ï¼š

```python
# å‡è®¾ running = [A, B, C], scheduled_seqs = [A, B]
# è°ƒåº¦å A, B è¢«å–å‡º
# running = [C]
# éœ€è¦æŠŠ A, B æ”¾å›é˜Ÿé¦–

# reversed([A, B]) = [B, A]
# extendleft([B, A]) => running = [A, B, C]
```

ä¿æŒåºåˆ—çš„ä¼˜å…ˆçº§é¡ºåºã€‚

> ğŸ’¡ **è®¾è®¡æ€æƒ³**ï¼šPrefill ä¼˜å…ˆä½“ç°äº†ã€Œæ–°è¯·æ±‚ä¼˜å…ˆã€ç­–ç•¥ï¼Œé¿å…é¥ªé¥¿é—®é¢˜ã€‚è¿™ç§è®¾è®¡è®©æ–°ç”¨æˆ·ä¸å¿…ç­‰å¾…æ—§è¯·æ±‚å®Œæˆï¼Œæå‡äº†ç³»ç»Ÿçš„å“åº”æ€§ã€‚

---

## 6.6 æŠ¢å æœºåˆ¶

```python
def preempt(self, seq: Sequence):
    seq.status = SequenceStatus.WAITING     # å›åˆ°ç­‰å¾…çŠ¶æ€
    self.block_manager.deallocate(seq)      # é‡Šæ”¾ KV Cache
    self.waiting.appendleft(seq)            # åŠ å…¥ç­‰å¾…é˜Ÿåˆ—å¤´éƒ¨
```

### æŠ¢å ç¤ºæ„å›¾

```mermaid
sequenceDiagram
    participant Sched as è°ƒåº¦å™¨
    participant BM as BlockManager
    participant Seq as è¢«æŠ¢å åºåˆ—
    
    Sched->>Seq: status = WAITING
    Sched->>BM: deallocate(seq)
    BM->>BM: é‡Šæ”¾æ‰€æœ‰å—
    BM->>BM: æ¸…ç©º block_table
    Sched->>Sched: waiting.appendleft(seq)
    Note right of Sched: æ”¾åˆ°é˜Ÿé¦–<br/>ä¸‹æ¬¡ä¼˜å…ˆè°ƒåº¦
```

### æŠ¢å ç­–ç•¥

| ç­–ç•¥ | å®ç° | è¯´æ˜ |
|:---|:---|:---|
| LIFO | `running.pop()` | åè¿›å…¥çš„å…ˆè¢«æŠ¢å  |
| ä¼˜å…ˆæ¢å¤ | `waiting.appendleft()` | è¢«æŠ¢å çš„ä¼˜å…ˆé‡æ–°è°ƒåº¦ |

> ğŸ’¡ **è®¾è®¡æ€æƒ³**ï¼šLIFO æŠ¢å ç­–ç•¥é€‰æ‹©æœ€è¿‘åŠ å…¥çš„åºåˆ—ï¼Œå› ä¸ºè¿™äº›åºåˆ—é€šå¸¸å·²ç¼“å­˜çš„ KV æ•°æ®æœ€å°‘ï¼ŒæŠ¢å æˆæœ¬æœ€ä½ã€‚è¢«æŠ¢å çš„åºåˆ—åŠ å…¥ `waiting` é˜Ÿé¦–è€Œéé˜Ÿå°¾ï¼Œä¿è¯ä¸‹æ¬¡ä¼˜å…ˆæ¢å¤ã€‚

---

## 6.7 åå¤„ç†

```python
def postprocess(self, seqs: list[Sequence], token_ids: list[int]) -> list[bool]:
    for seq, token_id in zip(seqs, token_ids):
        seq.append_token(token_id)                      # è¿½åŠ ç”Ÿæˆçš„ token
        
        # æ£€æŸ¥ç»ˆæ­¢æ¡ä»¶
        if (not seq.ignore_eos and token_id == self.eos) or \
           seq.num_completion_tokens == seq.max_tokens:
            seq.status = SequenceStatus.FINISHED
            self.block_manager.deallocate(seq)
            self.running.remove(seq)
```

### é€è¡Œè§£æ

| è¡Œå· | æ“ä½œ | è¯´æ˜ |
|:---:|:---|:---|
| 1 | `zip(seqs, token_ids)` | ä¸€ä¸€å¯¹åº”å¤„ç† |
| 2 | `seq.append_token(token_id)` | æ›´æ–°åºåˆ—çš„ token_ids |
| 3-4 | ç»ˆæ­¢æ¡ä»¶æ£€æŸ¥ | EOS æˆ–è¾¾åˆ° max_tokens |
| 5 | æ›´æ–°çŠ¶æ€ | æ ‡è®°ä¸ºå®Œæˆ |
| 6 | é‡Šæ”¾èµ„æº | å½’è¿˜ KV Cache |
| 7 | ç§»å‡ºé˜Ÿåˆ— | ä» running ç§»é™¤ |

> ğŸ’¡ **è®¾è®¡æ€æƒ³**ï¼š`postprocess` å°† token è¿½åŠ å’Œç»ˆæ­¢æ£€æŸ¥èåˆåœ¨åŒä¸€ä¸ªæ–¹æ³•ä¸­ï¼Œé¿å…å¤šæ¬¡éå†åºåˆ—åˆ—è¡¨ã€‚è¿™æ˜¯ã€Œå•æ¬¡éå†å¤šæ“ä½œã€çš„æ€§èƒ½ä¼˜åŒ–æ¨¡å¼ã€‚

### ç»ˆæ­¢æ¡ä»¶

```mermaid
graph TD
    A{ignore_eos?}
    A -->|æ˜¯| B{è¾¾åˆ° max_tokens?}
    A -->|å¦| C{ç”Ÿæˆäº† EOS?}
    B -->|æ˜¯| D[ç»ˆæ­¢]
    B -->|å¦| E[ç»§ç»­ç”Ÿæˆ]
    C -->|æ˜¯| D
    C -->|å¦| B
```

---

## 6.8 å®Œæ•´è°ƒåº¦æµç¨‹

```mermaid
sequenceDiagram
    participant User as ç”¨æˆ·
    participant Engine as LLMEngine
    participant Sched as Scheduler
    participant BM as BlockManager
    participant Runner as ModelRunner
    
    User->>Engine: generate(prompts)
    
    loop æ¯ä¸ª prompt
        Engine->>Sched: add(seq)
        Sched->>Sched: waiting.append(seq)
    end
    
    loop ç›´åˆ° is_finished()
        Engine->>Sched: schedule()
        
        alt æœ‰ waiting åºåˆ—
            Sched->>BM: allocate(seq)
            Sched-->>Engine: (seqs, is_prefill=True)
        else åªæœ‰ running åºåˆ—
            Sched->>BM: may_append(seq)
            Sched-->>Engine: (seqs, is_prefill=False)
        end
        
        Engine->>Runner: run(seqs, is_prefill)
        Runner-->>Engine: token_ids
        
        Engine->>Sched: postprocess(seqs, token_ids)
        Sched->>Sched: æ›´æ–°åºåˆ—çŠ¶æ€
        
        alt åºåˆ—å®Œæˆ
            Sched->>BM: deallocate(seq)
            Sched->>Sched: running.remove(seq)
        end
    end
    
    Engine-->>User: outputs
```

---

## 6.9 è°ƒåº¦ç¤ºä¾‹

### åœºæ™¯è®¾ç½®

```python
max_num_seqs = 4
max_num_batched_tokens = 1024
```

### åˆå§‹çŠ¶æ€

```
waiting: [Seq1(500), Seq2(300), Seq3(400), Seq4(200)]
running: []
```

### ç¬¬ä¸€è½®è°ƒåº¦ï¼ˆPrefillï¼‰

```
1. Seq1: 500 < 1024, åˆ†é…æˆåŠŸ
   - num_batched_tokens = 500
   
2. Seq2: 500 + 300 = 800 < 1024, åˆ†é…æˆåŠŸ
   - num_batched_tokens = 800
   
3. Seq3: 800 + 400 = 1200 > 1024, åœæ­¢

ç»“æœ:
waiting: [Seq3(400), Seq4(200)]
running: [Seq1(500), Seq2(300)]
scheduled: [Seq1, Seq2], is_prefill=True
```

### ç¬¬äºŒè½®è°ƒåº¦ï¼ˆDecodeï¼‰

å‡è®¾ Prefill å®Œæˆï¼Œæ‰€æœ‰åºåˆ—éƒ½å·²åˆ†é…ï¼š

```
waiting: []
running: [Seq1(501), Seq2(301)]

æ¯ä¸ªåºåˆ—åªéœ€å¤„ç† 1 ä¸ª token
scheduled: [Seq1, Seq2], is_prefill=False
```

### æŠ¢å åœºæ™¯

å‡è®¾å†…å­˜ä¸è¶³ï¼š

```
1. å–å‡º Seq1ï¼Œæ£€æŸ¥ can_append
2. å†…å­˜ä¸è¶³ï¼ŒæŠ¢å  Seq2ï¼ˆLIFOï¼‰
3. é‡Šæ”¾ Seq2 çš„ KV Cache
4. é‡æ–°æ£€æŸ¥ï¼ŒSeq1 å¯ä»¥è¿½åŠ 

ç»“æœ:
waiting: [Seq2(301)]  # Seq2 è¢«æŠ¢å 
running: [Seq1(502)]
scheduled: [Seq1], is_prefill=False
```

---

## 6.10 æœ¬ç« å°ç»“

æœ¬ç« æˆ‘ä»¬å­¦ä¹ äº†ï¼š

1. **è°ƒåº¦å™¨ç»“æ„**ï¼š
   - waiting å’Œ running ä¸¤ä¸ªé˜Ÿåˆ—
   - BlockManager ç®¡ç†å†…å­˜

2. **Prefill è°ƒåº¦**ï¼š
   - æ‰¹é‡å¤„ç†ç­‰å¾…é˜Ÿåˆ—
   - æ£€æŸ¥ token æ•°å’Œå†…å­˜é™åˆ¶

3. **Decode è°ƒåº¦**ï¼š
   - å¤„ç†è¿è¡Œé˜Ÿåˆ—
   - æŒ‰éœ€æŠ¢å é‡Šæ”¾å†…å­˜

4. **æŠ¢å æœºåˆ¶**ï¼š
   - LIFO ç­–ç•¥
   - ä¼˜å…ˆæ¢å¤

5. **åå¤„ç†**ï¼š
   - è¿½åŠ  token
   - æ£€æŸ¥ç»ˆæ­¢æ¡ä»¶
   - é‡Šæ”¾èµ„æº

---

**ä¸‹ä¸€ç« ** â†’ [07 LLM å¼•æ“è¯¦è§£](07_llm_engine.md)
